{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "from scipy.ndimage import zoom\n",
    "from keras.applications import VGG16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv #REMEMBER TO ADD THIS TO REQUIREMENTS!!!!!!\n",
    "from keras import layers, models, Model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(wav_path, sr=16000):\n",
    "\n",
    "    y, sr = librosa.load(wav_path)\n",
    "\n",
    "    # Create mel spectrogram\n",
    "    mel_spect = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_mels=128,  # Number of mel bands\n",
    "        fmax=8000    # Maximum frequency\n",
    "    )\n",
    "\n",
    "    # Convert to log scale and return\n",
    "    return np.array(librosa.power_to_db(mel_spect, ref=np.max))\n",
    "\n",
    "wav_path = '../raw_data/test/0_4753_4846_OffMenu263.wav'\n",
    "spectrogram = create_spectrogram(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 216)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_spectrogram(spectrogram, output_size):\n",
    "    sp_row, sp_col = spectrogram.shape\n",
    "    out_row, out_col = output_size\n",
    "    resized_spec = zoom(spectrogram, (out_row/sp_row, out_col/sp_col))\n",
    "    return resized_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaler(spectrogram):\n",
    "    min_val = np.min(spectrogram)\n",
    "    max_val = np.max(spectrogram)\n",
    "\n",
    "    normalised_spectrogram = (spectrogram - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalised_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_spectrogram(spectrogram):\n",
    "    temp_spectogrram =  np.stack((spectrogram, spectrogram, spectrogram), axis=2)\n",
    "    # final_spec = np.expand_dims(temp_spectogrram, axis=0)\n",
    "    return temp_spectogrram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through all clip files and generate spectrograms\n",
    "def get_features_model (folder_path):\n",
    "    spectrograms = [] # This will store the spectrograms of each clip\n",
    "    labels = []  # This will store the labels of each clip\n",
    "    seconds = []  # Number of seconds to consider for each clip\n",
    "    durations = []  # Duration of the full audio file\n",
    "    podcast_names = []  # This will store the podcast names of each clip\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    file_list = os.listdir(folder_path)\n",
    "    print(f\"Processing files: total {len(file_list)}\")\n",
    "    for filename in file_list:\n",
    "        # Check if the file is a .wav or .mp3 (you can adjust this as needed)\n",
    "        if filename.endswith('.wav') or filename.endswith('.mp3'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Split the filename by underscore\n",
    "            filename_parts = filename.split('_')\n",
    "\n",
    "            # Extract 0 or 1 from the first part of the filename (label: ad or no_ad)\n",
    "            is_ad = int(filename_parts[0])  # First part is the label\n",
    "\n",
    "            # Extract the start time in seconds (second part of the filename)\n",
    "            start_time = int(filename_parts[1])  # Second part is the start time in seconds\n",
    "\n",
    "            # Extract the total duration (third part of the filename)\n",
    "            duration = int(filename_parts[2])  # Third part is the total duration of the podcast\n",
    "\n",
    "             # Extract the podcast name (four part of the filename)\n",
    "            podcast_name = filename_parts[3].replace('.wav', '')  # Third part is the total duration of the podcast\n",
    "\n",
    "            # Create spectrogram and convert to numpy array\n",
    "            spectrogram = create_spectrogram(file_path)\n",
    "            resized_spectrogram =resize_spectrogram(spectrogram, (96,64))\n",
    "            scaled_spectrogram = minmax_scaler(resized_spectrogram)\n",
    "            reshaped_spectrogram = reshape_spectrogram(scaled_spectrogram)\n",
    "\n",
    "            # Append the numpy array to the list\n",
    "            spectrograms.append(reshaped_spectrogram)\n",
    "            labels.append(is_ad)\n",
    "            seconds.append(start_time)\n",
    "            durations.append(duration)\n",
    "            podcast_names.append(podcast_name)\n",
    "\n",
    "    return spectrograms, labels, seconds, durations, podcast_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: total 4800\n"
     ]
    }
   ],
   "source": [
    "# Data folder path: Change this to the path where your audio clips are stored\n",
    "folder_path = '../raw_data/OffMenu263'\n",
    "all_spectrograms = get_features_model(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_spectrograms[0])\n",
    "y = np.array(all_spectrograms[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 96, 64, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.6409163 , 0.6409163 , 0.6409163 ],\n",
       "         [0.38479653, 0.38479653, 0.38479653],\n",
       "         [0.37839317, 0.37839317, 0.37839317],\n",
       "         ...,\n",
       "         [0.19931024, 0.19931024, 0.19931024],\n",
       "         [0.19428426, 0.19428426, 0.19428426],\n",
       "         [0.57369953, 0.57369953, 0.57369953]],\n",
       "\n",
       "        [[0.72761166, 0.72761166, 0.72761166],\n",
       "         [0.6307602 , 0.6307602 , 0.6307602 ],\n",
       "         [0.67127293, 0.67127293, 0.67127293],\n",
       "         ...,\n",
       "         [0.2568575 , 0.2568575 , 0.2568575 ],\n",
       "         [0.50509113, 0.50509113, 0.50509113],\n",
       "         [0.6777614 , 0.6777614 , 0.6777614 ]],\n",
       "\n",
       "        [[0.871038  , 0.871038  , 0.871038  ],\n",
       "         [0.7902225 , 0.7902225 , 0.7902225 ],\n",
       "         [0.6498148 , 0.6498148 , 0.6498148 ],\n",
       "         ...,\n",
       "         [0.69515383, 0.69515383, 0.69515383],\n",
       "         [0.69425166, 0.69425166, 0.69425166],\n",
       "         [0.67825186, 0.67825186, 0.67825186]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3666606 , 0.3666606 , 0.3666606 ],\n",
       "         [0.31119344, 0.31119344, 0.31119344],\n",
       "         [0.32175314, 0.32175314, 0.32175314],\n",
       "         ...,\n",
       "         [0.3102371 , 0.3102371 , 0.3102371 ],\n",
       "         [0.3332682 , 0.3332682 , 0.3332682 ],\n",
       "         [0.28707498, 0.28707498, 0.28707498]],\n",
       "\n",
       "        [[0.3653847 , 0.3653847 , 0.3653847 ],\n",
       "         [0.3121922 , 0.3121922 , 0.3121922 ],\n",
       "         [0.11181507, 0.11181507, 0.11181507],\n",
       "         ...,\n",
       "         [0.1935591 , 0.1935591 , 0.1935591 ],\n",
       "         [0.3189765 , 0.3189765 , 0.3189765 ],\n",
       "         [0.34890756, 0.34890756, 0.34890756]],\n",
       "\n",
       "        [[0.3695838 , 0.3695838 , 0.3695838 ],\n",
       "         [0.26503336, 0.26503336, 0.26503336],\n",
       "         [0.04556528, 0.04556528, 0.04556528],\n",
       "         ...,\n",
       "         [0.24691252, 0.24691252, 0.24691252],\n",
       "         [0.3051632 , 0.3051632 , 0.3051632 ],\n",
       "         [0.32875037, 0.32875037, 0.32875037]]],\n",
       "\n",
       "\n",
       "       [[[0.64271784, 0.64271784, 0.64271784],\n",
       "         [0.5187474 , 0.5187474 , 0.5187474 ],\n",
       "         [0.09209413, 0.09209413, 0.09209413],\n",
       "         ...,\n",
       "         [0.3520195 , 0.3520195 , 0.3520195 ],\n",
       "         [0.29851237, 0.29851237, 0.29851237],\n",
       "         [0.49466687, 0.49466687, 0.49466687]],\n",
       "\n",
       "        [[0.78337514, 0.78337514, 0.78337514],\n",
       "         [0.7920283 , 0.7920283 , 0.7920283 ],\n",
       "         [0.29891244, 0.29891244, 0.29891244],\n",
       "         ...,\n",
       "         [0.43752947, 0.43752947, 0.43752947],\n",
       "         [0.45958647, 0.45958647, 0.45958647],\n",
       "         [0.5922909 , 0.5922909 , 0.5922909 ]],\n",
       "\n",
       "        [[0.89395124, 0.89395124, 0.89395124],\n",
       "         [0.83785105, 0.83785105, 0.83785105],\n",
       "         [0.29424384, 0.29424384, 0.29424384],\n",
       "         ...,\n",
       "         [0.7589856 , 0.7589856 , 0.7589856 ],\n",
       "         [0.80217177, 0.80217177, 0.80217177],\n",
       "         [0.7535147 , 0.7535147 , 0.7535147 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28179216, 0.28179216, 0.28179216],\n",
       "         [0.16854577, 0.16854577, 0.16854577],\n",
       "         [0.03525167, 0.03525167, 0.03525167],\n",
       "         ...,\n",
       "         [0.42291912, 0.42291912, 0.42291912],\n",
       "         [0.20513399, 0.20513399, 0.20513399],\n",
       "         [0.38267738, 0.38267738, 0.38267738]],\n",
       "\n",
       "        [[0.25397557, 0.25397557, 0.25397557],\n",
       "         [0.17196979, 0.17196979, 0.17196979],\n",
       "         [0.03619178, 0.03619178, 0.03619178],\n",
       "         ...,\n",
       "         [0.33257815, 0.33257815, 0.33257815],\n",
       "         [0.19173865, 0.19173865, 0.19173865],\n",
       "         [0.3764027 , 0.3764027 , 0.3764027 ]],\n",
       "\n",
       "        [[0.2414305 , 0.2414305 , 0.2414305 ],\n",
       "         [0.17471713, 0.17471713, 0.17471713],\n",
       "         [0.02918661, 0.02918661, 0.02918661],\n",
       "         ...,\n",
       "         [0.2775824 , 0.2775824 , 0.2775824 ],\n",
       "         [0.1626342 , 0.1626342 , 0.1626342 ],\n",
       "         [0.33658978, 0.33658978, 0.33658978]]],\n",
       "\n",
       "\n",
       "       [[[0.48499867, 0.48499867, 0.48499867],\n",
       "         [0.43886223, 0.43886223, 0.43886223],\n",
       "         [0.3847704 , 0.3847704 , 0.3847704 ],\n",
       "         ...,\n",
       "         [0.51095676, 0.51095676, 0.51095676],\n",
       "         [0.2975774 , 0.2975774 , 0.2975774 ],\n",
       "         [0.4711726 , 0.4711726 , 0.4711726 ]],\n",
       "\n",
       "        [[0.48770475, 0.48770475, 0.48770475],\n",
       "         [0.48711663, 0.48711663, 0.48711663],\n",
       "         [0.3259326 , 0.3259326 , 0.3259326 ],\n",
       "         ...,\n",
       "         [0.62014765, 0.62014765, 0.62014765],\n",
       "         [0.4125543 , 0.4125543 , 0.4125543 ],\n",
       "         [0.4643651 , 0.4643651 , 0.4643651 ]],\n",
       "\n",
       "        [[0.49094474, 0.49094474, 0.49094474],\n",
       "         [0.45950556, 0.45950556, 0.45950556],\n",
       "         [0.3012132 , 0.3012132 , 0.3012132 ],\n",
       "         ...,\n",
       "         [0.5149938 , 0.5149938 , 0.5149938 ],\n",
       "         [0.4600664 , 0.4600664 , 0.4600664 ],\n",
       "         [0.46654946, 0.46654946, 0.46654946]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14497782, 0.14497782, 0.14497782],\n",
       "         [0.6819545 , 0.6819545 , 0.6819545 ],\n",
       "         [0.34841505, 0.34841505, 0.34841505],\n",
       "         ...,\n",
       "         [0.5311154 , 0.5311154 , 0.5311154 ],\n",
       "         [0.74802774, 0.74802774, 0.74802774],\n",
       "         [0.5125615 , 0.5125615 , 0.5125615 ]],\n",
       "\n",
       "        [[0.15081225, 0.15081225, 0.15081225],\n",
       "         [0.680915  , 0.680915  , 0.680915  ],\n",
       "         [0.26491767, 0.26491767, 0.26491767],\n",
       "         ...,\n",
       "         [0.511943  , 0.511943  , 0.511943  ],\n",
       "         [0.6841042 , 0.6841042 , 0.6841042 ],\n",
       "         [0.5103182 , 0.5103182 , 0.5103182 ]],\n",
       "\n",
       "        [[0.09508799, 0.09508799, 0.09508799],\n",
       "         [0.69567245, 0.69567245, 0.69567245],\n",
       "         [0.2363051 , 0.2363051 , 0.2363051 ],\n",
       "         ...,\n",
       "         [0.37366736, 0.37366736, 0.37366736],\n",
       "         [0.6970564 , 0.6970564 , 0.6970564 ],\n",
       "         [0.49457294, 0.49457294, 0.49457294]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.04260187, 0.04260187, 0.04260187],\n",
       "         [0.10331207, 0.10331207, 0.10331207],\n",
       "         [0.11254239, 0.11254239, 0.11254239],\n",
       "         ...,\n",
       "         [0.2765602 , 0.2765602 , 0.2765602 ],\n",
       "         [0.42088172, 0.42088172, 0.42088172],\n",
       "         [0.6300499 , 0.6300499 , 0.6300499 ]],\n",
       "\n",
       "        [[0.06988989, 0.06988989, 0.06988989],\n",
       "         [0.16616695, 0.16616695, 0.16616695],\n",
       "         [0.14151756, 0.14151756, 0.14151756],\n",
       "         ...,\n",
       "         [0.27172628, 0.27172628, 0.27172628],\n",
       "         [0.3916863 , 0.3916863 , 0.3916863 ],\n",
       "         [0.65927243, 0.65927243, 0.65927243]],\n",
       "\n",
       "        [[0.19516368, 0.19516368, 0.19516368],\n",
       "         [0.15200227, 0.15200227, 0.15200227],\n",
       "         [0.13060799, 0.13060799, 0.13060799],\n",
       "         ...,\n",
       "         [0.6665045 , 0.6665045 , 0.6665045 ],\n",
       "         [0.6739647 , 0.6739647 , 0.6739647 ],\n",
       "         [0.69577664, 0.69577664, 0.69577664]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.04260187, 0.04260187, 0.04260187],\n",
       "         [0.0471394 , 0.0471394 , 0.0471394 ],\n",
       "         [0.05268458, 0.05268458, 0.05268458],\n",
       "         ...,\n",
       "         [0.24308169, 0.24308169, 0.24308169],\n",
       "         [0.16057284, 0.16057284, 0.16057284],\n",
       "         [0.31391066, 0.31391066, 0.31391066]],\n",
       "\n",
       "        [[0.04260187, 0.04260187, 0.04260187],\n",
       "         [0.04715916, 0.04715916, 0.04715916],\n",
       "         [0.05583258, 0.05583258, 0.05583258],\n",
       "         ...,\n",
       "         [0.17743826, 0.17743826, 0.17743826],\n",
       "         [0.09862501, 0.09862501, 0.09862501],\n",
       "         [0.21562165, 0.21562165, 0.21562165]],\n",
       "\n",
       "        [[0.04260187, 0.04260187, 0.04260187],\n",
       "         [0.04260206, 0.04260206, 0.04260206],\n",
       "         [0.04259453, 0.04259453, 0.04259453],\n",
       "         ...,\n",
       "         [0.13770735, 0.13770735, 0.13770735],\n",
       "         [0.13334732, 0.13334732, 0.13334732],\n",
       "         [0.20660193, 0.20660193, 0.20660193]]],\n",
       "\n",
       "\n",
       "       [[[0.62160975, 0.62160975, 0.62160975],\n",
       "         [0.41969174, 0.41969174, 0.41969174],\n",
       "         [0.30861327, 0.30861327, 0.30861327],\n",
       "         ...,\n",
       "         [0.19487472, 0.19487472, 0.19487472],\n",
       "         [0.2015675 , 0.2015675 , 0.2015675 ],\n",
       "         [0.04478453, 0.04478453, 0.04478453]],\n",
       "\n",
       "        [[0.6307067 , 0.6307067 , 0.6307067 ],\n",
       "         [0.5444233 , 0.5444233 , 0.5444233 ],\n",
       "         [0.34592432, 0.34592432, 0.34592432],\n",
       "         ...,\n",
       "         [0.27611825, 0.27611825, 0.27611825],\n",
       "         [0.420098  , 0.420098  , 0.420098  ],\n",
       "         [0.11911016, 0.11911016, 0.11911016]],\n",
       "\n",
       "        [[0.6541378 , 0.6541378 , 0.6541378 ],\n",
       "         [0.6146814 , 0.6146814 , 0.6146814 ],\n",
       "         [0.41325143, 0.41325143, 0.41325143],\n",
       "         ...,\n",
       "         [0.6384121 , 0.6384121 , 0.6384121 ],\n",
       "         [0.5730465 , 0.5730465 , 0.5730465 ],\n",
       "         [0.28782138, 0.28782138, 0.28782138]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2643843 , 0.2643843 , 0.2643843 ],\n",
       "         [0.36394376, 0.36394376, 0.36394376],\n",
       "         [0.46755826, 0.46755826, 0.46755826],\n",
       "         ...,\n",
       "         [0.21389034, 0.21389034, 0.21389034],\n",
       "         [0.0288142 , 0.0288142 , 0.0288142 ],\n",
       "         [0.00789209, 0.00789209, 0.00789209]],\n",
       "\n",
       "        [[0.1912132 , 0.1912132 , 0.1912132 ],\n",
       "         [0.35941502, 0.35941502, 0.35941502],\n",
       "         [0.44901493, 0.44901493, 0.44901493],\n",
       "         ...,\n",
       "         [0.18816923, 0.18816923, 0.18816923],\n",
       "         [0.03968503, 0.03968503, 0.03968503],\n",
       "         [0.00789209, 0.00789209, 0.00789209]],\n",
       "\n",
       "        [[0.1687224 , 0.1687224 , 0.1687224 ],\n",
       "         [0.32046023, 0.32046023, 0.32046023],\n",
       "         [0.43606746, 0.43606746, 0.43606746],\n",
       "         ...,\n",
       "         [0.1805605 , 0.1805605 , 0.1805605 ],\n",
       "         [0.01898796, 0.01898796, 0.01898796],\n",
       "         [0.00789209, 0.00789209, 0.00789209]]],\n",
       "\n",
       "\n",
       "       [[[0.55609536, 0.55609536, 0.55609536],\n",
       "         [0.5442994 , 0.5442994 , 0.5442994 ],\n",
       "         [0.4363542 , 0.4363542 , 0.4363542 ],\n",
       "         ...,\n",
       "         [0.4950027 , 0.4950027 , 0.4950027 ],\n",
       "         [0.44053912, 0.44053912, 0.44053912],\n",
       "         [0.5947866 , 0.5947866 , 0.5947866 ]],\n",
       "\n",
       "        [[0.7520874 , 0.7520874 , 0.7520874 ],\n",
       "         [0.8927039 , 0.8927039 , 0.8927039 ],\n",
       "         [0.85378295, 0.85378295, 0.85378295],\n",
       "         ...,\n",
       "         [0.49044576, 0.49044576, 0.49044576],\n",
       "         [0.47870082, 0.47870082, 0.47870082],\n",
       "         [0.59947807, 0.59947807, 0.59947807]],\n",
       "\n",
       "        [[0.7319925 , 0.7319925 , 0.7319925 ],\n",
       "         [0.9011716 , 0.9011716 , 0.9011716 ],\n",
       "         [0.88941246, 0.88941246, 0.88941246],\n",
       "         ...,\n",
       "         [0.7342293 , 0.7342293 , 0.7342293 ],\n",
       "         [0.7175501 , 0.7175501 , 0.7175501 ],\n",
       "         [0.72914886, 0.72914886, 0.72914886]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.33270606, 0.33270606, 0.33270606],\n",
       "         [0.24838416, 0.24838416, 0.24838416],\n",
       "         [0.32115892, 0.32115892, 0.32115892],\n",
       "         ...,\n",
       "         [0.00649477, 0.00649477, 0.00649477],\n",
       "         [0.00811075, 0.00811075, 0.00811075],\n",
       "         [0.00699811, 0.00699811, 0.00699811]],\n",
       "\n",
       "        [[0.28302613, 0.28302613, 0.28302613],\n",
       "         [0.22933264, 0.22933264, 0.22933264],\n",
       "         [0.27553734, 0.27553734, 0.27553734],\n",
       "         ...,\n",
       "         [0.00698301, 0.00698301, 0.00698301],\n",
       "         [0.00680136, 0.00680136, 0.00680136],\n",
       "         [0.0069983 , 0.0069983 , 0.0069983 ]],\n",
       "\n",
       "        [[0.29090258, 0.29090258, 0.29090258],\n",
       "         [0.25225407, 0.25225407, 0.25225407],\n",
       "         [0.23949689, 0.23949689, 0.23949689],\n",
       "         ...,\n",
       "         [0.00718627, 0.00718627, 0.00718627],\n",
       "         [0.00699434, 0.00699434, 0.00699434],\n",
       "         [0.0069983 , 0.0069983 , 0.0069983 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16\n",
    "(96,64) optimal shape\n",
    "\n",
    "base_model = \n",
    "include_top=False (you don't want top tlayers)\n",
    "model = models,Sequential() *add this layer sigmoid activation at end\n",
    "\n",
    "X = np.random.rand(samplenum, 96, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram_db, sr, hop_length):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    librosa.display.specshow(spectrogram_db, sr=sr, hop_length=hop_length)\n",
    "    plt.title('Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(output_path)\n",
    "    # plt.close()\n",
    "plot_spectrogram(spectrogram, 16000, 1)\n",
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 Model\n",
    "# Import VGG16 and set the necessary arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(96,64,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze convolutional blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# Make sure you have frozen the correct layers\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x = base_model.output\n",
    "# model = base_model.Sequential()\n",
    "\n",
    "# # First convolutional layer\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], X.shape[3])))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Second convolutional layer\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Third convolutional layer\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# # Flatten the output and add Dense layers\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 64, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1], X_train.shape[2], X_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_vgg_model():\n",
    "#     base_model = tf.keras.applications.VGG16(\n",
    "#         include_top=False,\n",
    "#         input_shape=(96, 64, 1),\n",
    "#         weights=None)\n",
    "\n",
    "#     # specific layers for ad detection\n",
    "#     model = models.Sequential([\n",
    "#         base_model,\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(1, activation='sigmoid')  # ad vs. non-ad\n",
    "#     ])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 96, 64, 3), dtype=float32, sparse=False, name=keras_tensor_37>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "\n",
    "# First convolutional layer\n",
    "x = layers.Conv2D(32,(3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]))(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "\n",
    "# # Second convolutional layer\n",
    "# x = layer.Conv2D(64, (3, 3), activation='relu')\n",
    "# x = layer.MaxPooling2D((2, 2))\n",
    "\n",
    "# # Third convolutional layer\n",
    "# x = layer.Conv2D(64, (3, 3), activation='relu')\n",
    "\n",
    "# create basic convo layer + maxpooling\n",
    "x = layers.Flatten()(x) # Flatten dimensions for use in FC layers\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "# x = layer.Dense(256, activation='relu')(x)\n",
    "x = layers.Dense(8, activation='sigmoid')(x)\n",
    "transfer_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# # why is it useful to have pooling layer after convolutional layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Conv2D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 3 from 2 for '{{node functional_5_1/conv2d_5_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](functional_5_1/block5_pool_1/MaxPool2d, functional_5_1/conv2d_5_1/convolution/ReadVariableOp)' with input shapes: [1,3,2,512], [3,3,512,32].\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(1, 3, 2, 512), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# learning_rate= 0.01\u001b[39;00m\n\u001b[1;32m      2\u001b[0m transfer_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                        optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                        metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtransfer_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/podcast-ad-skipper/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/podcast-ad-skipper/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Conv2D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 3 from 2 for '{{node functional_5_1/conv2d_5_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](functional_5_1/block5_pool_1/MaxPool2d, functional_5_1/conv2d_5_1/convolution/ReadVariableOp)' with input shapes: [1,3,2,512], [3,3,512,32].\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(1, 3, 2, 512), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# learning_rate= 0.01\n",
    "transfer_model.compile(loss=\"categorical_crossentropy\",\n",
    "                       optimizer='adam',\n",
    "                       metrics=[\"accuracy\"])\n",
    "history = transfer_model.fit(X_train,\n",
    "                             y_train,\n",
    "                             batch_size = 1,\n",
    "                             epochs=50,\n",
    "                             validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podcast-ad-skipper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
